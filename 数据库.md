# 数据库

<!--Note-->
## 资料

- 《MySQL 必知必会》
- [Leetcode](https://leetcode.com/problemset/database/)
- 《高性能 MySQL》
- 《MySQL 技术内幕》
- 《Redis 设计与实现》
- 《Redis 实战》
- 《大规模分布式存储系统》
<!--/Note-->

## SQL

### 手写分组查询

#### 分组数据

##### 创建分组

```
SELECT col, COUNT(*) AS num_col
FROM mytable
GROUP BY col;
```
根据col的值分组，相同的值为一组，然后num_col显示每组的行数。

GROUP BY子句指示MySQL分组数据，规定如下：
- GROUP BY子句可以包含任意数目的列，使得能够对分组进行嵌套。
- GROUP BY子句中指定的必须是列或表达式，不能使用别名。
- 多行NULL组会作为一个分组返回。
- GROUP BY子句必须出现在WHERE子句之后，ORDER BY子句之前。

##### 过滤分组

HAVING非常类似于WHERE，但WHERE过滤行，而HAVING过滤分组。
```
SELECT col1, COUNT(*) AS num_col
FROM mytable
WHERE col2 >= 10
GROUP BY col1
HAVING COUNT(*) >= 2;
```

##### 分组和排序

- ORDER BY按照排列顺序产生输出；GROUP BY虽然经常按分组顺序输出，但不总是这样。
- 一般GROUP BY和ORDER BY一起使用，保证数据正确排序。不能仅依赖GROUP BY排列数据。

```
SELECT col, COUNT(*) AS num_col
FROM mytable
GROUP BY col	
HAVING COUNT(*) > 2
ORDER BY num_col;
```

###### ORDER BY与GROUP BY

##### SELECT子句顺序

SELECT语句中子句的顺序如下：
SELECT
FROM
WHERE
GROUP BY
HAVING
ORDER BY
LIMIT

### 手写连接查询

#### 使用不同类型的联结

##### 自联结

```
SELECT a1.col1, a2.col2 
FROM mytable AS a1, mytable AS a2
WHERE a1.col3 = a2.col3
AND a2.col1 = 'val';
```
等同于如下子查询：
```
SELECT col1, col2
FROM mytable
WHERE col3 = (SELECT col3
			  FROM mytable
              WHERE col1 = 'val');
```
使用自联结而不用子查询，因为有时候处理联结远比处理子查询快的多。

##### 自然联结

自然联结排除多次出现，使每个列只返回一次。
一般是通过对表使用通配符（`SELECT *`),对所有其他表的列使用明确的子集来完成。
```
SELECT a.*, b.col1
FROM mytable1 AS a, mytable2 AS b
WHERE a.col2 = b.col2;
```

##### 外部联结

与内部联结不同的是，外部联结还包含没有关联行的行。分为左外连接，右外连接以及全外连接，左外连接就是保留左表没有关联的行。
```
SELECT mytable1_col, mytable2_col
FROM mytable1 LEFT OUTER JOIN mytable2
ON mytable1.col = mytable2.col;
```

##### 使用带聚集函数的联结

```
SELECT mytable1.col1, COUNT(mytable2.col2) AS num_col2
FROM mytable1 INNER JOIN mytable2
ON mytable1.col1 = mytable2.col1
GROUP BY mytable1.col1;
```
对mytable1.col1分组后，计算每组mytable2.col2列的行数。

### 连接与子查询

### drop、delete、truncate

### 视图

- 视图的作用，以及何时能更新视图。

### 存储过程

### 触发器

## 系统原理

### 事务

#### ACID

##### 原子性（atomicity）

事务的所有操作在数据库中要么全部正确反映出来，要么完全不反映。

如果事务没能完成它的执行，数据库系统从日志中恢复旧值，使得看上去事务从未执行过。

##### 一致性（consistency）

如果一个事务作为原子从一个一致的数据库状态开始独立地执行，则事务结束时数据库也必须再次是一致的。

例如，一致性要求转账过程中事务的执行A账户、B账户之和不变。

##### 隔离性（isolation）

数据库必行采取特殊处理来确保事务正常执行而不被来自并发执行的数据库语句所干扰。

事务的隔离性确保事务并发执行后的系统状态和这些事务以某种次序一个接一个地执行后的状态是等价的。

##### 持久性（durability）

一个事务完成后，它对数据库的改变必须是永久的，即使出现系统故障。

确保事务做的更新在事务结束前已经写入磁盘或有关事务已执行的更新信息已写到磁盘上。

#####  

######  

#### 隔离级别

四大隔离级别，以及不可重复读和幻影读的出现原因。

##### 未提交读（read uncommitted）

解决更新丢失问题。如果一个事务已经开始写操作，那么其他事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现，即事物需要对某些数据进行修改必须对这些数据加 X 锁，读数据不需要加 S 锁。

###### 解决更新丢失

###### 排他锁实现

##### 已提交读（read committed）

解决了脏读问题。读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。这可以通过“瞬间共享读锁”和“排他写锁”实现， 即事物需要对某些数据进行修改必须对这些数据加 X 锁，读数据时需要加上 S 锁，当数据读取完成后立刻释放 S 锁，不用等到事务结束。

###### 解决脏读

###### 瞬时共享锁和排他锁实现

##### 可重复读（repeatable read）

禁止不可重复读取和脏读取，但是有时可能出现幻读数据。读取数据的事务将会禁止写事务(但允许读事务)，写事务则禁止任何其他事务。Mysql默认使用该隔离级别。这可以通过“共享读锁”和“排他写锁”实现，即事物需要对某些数据进行修改必须对这些数据加 X 锁，读数据时需要加上 S 锁，当数据读取完成并不立刻释放 S 锁，而是等到事务结束后再释放。

###### 解决不可重复读

###### 共享锁和排他锁实现

##### 可串行化（serializable）

解决了幻读的问题的。提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，不能并发执行。仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。

###### 解决幻读

### 锁

封锁的类型以及粒度，两段锁协议，隐式和显示锁定。

#### 多粒度

如果事务需要访问整个数据库，对数据库中的每个数据项加锁是很费时的，只发单个封锁整个数据库的加锁请求会更好。另一方面，如果事务只需存取少量数据项，就不应要求整个数据库加锁，否则将丧失并发性。因此，定义了**多级粒度（granularity）**机制。

##### 两种封锁粒度：行级锁以及表级锁。

##### 封锁粒度越小，系统开销就越大，并发程度就越高。

#### 锁的类型

##### 读写锁（行级锁）

- 共享型锁（shared-mode lock）：又称读锁，记为S，事务可读但不能写数据项。
- 排他型锁（exclusive-mode lock）：又称写锁，记为X，事务既可读又可写数据项。

如果事务 T1 在数据项 Q 上已加 B 型锁，事务 T2 要对数据项 Q 加 A 型锁，若事务 T2 可立即获得数据项 Q 上的锁，则 A 型锁与 B 型锁是相容的（compatible）。

锁的相容性矩阵comp：

- |   S   |   X 
- |   -   |   -
S | true  | false
X | false | false

- 如果不使用封锁，或者对数据项进行读写后立即解锁，可能会进入不一致的状态。
- 如果在申请对另一数据项加锁之前不对当前锁住的数据项解锁，则可能会发生死锁。
- 产生死锁显然比产生不一致状态要好，因为可以通过回滚事务加以解决。

# InnoDB 存储引擎
S 和 X 锁都是行锁，即对一行数据进行操作。

######  

###### InnoDB行级锁基于索引实现

##### 意向锁（表级锁）

- 意向共享锁（IS Lock）：事务想要获得一张表中某几行的共享锁
- 意向排他锁（IX Lock）：事务想要获得一张表中某几行的排他锁

######  

#### 加锁

##### 隐式加锁

###### 加行级锁之前，自动加表级锁

###### 根据隔离级别在需要时自动加锁

##### 显示加锁

###### 共享锁

####### SELECT ... LOCK IN SHARE MODE

###### 排他锁

####### SELECT ... FOR UPDATE

#### 死锁

##### 事务之间对资源交替访问

###### 场景

####### 事务 A 访问表 1，又访问表 2；事务 B 访问表 2，又访问表 1

###### 死锁避免

####### 访问多个表时，应参照相同的顺序锁定资源

##### 并发修改同一记录

###### 场景

####### 两事务同时查询同一记录，然后更新记录时，相互等待共享锁释放

###### 死锁避免

####### 乐观锁

####### SELECT ... FOR UPDATE

##### 死锁解决

###### InnoDB 会自动检测到死锁循环依赖，并对持有最少行级锁的事务进行回滚

###### 死锁超时机制

####### 查询时间达到锁等待超时时间后放弃锁请求

#### 两阶段封锁协议

**增长阶段（growing phase）**：事务可以获得锁，但不能释放锁。
**缩减阶段（shrinking phase）**：事务可以释放锁，但不能获得新锁。
最初，事务处于增长阶段，可加锁。事务一旦解锁，就进入缩减阶段，不能再加锁。

##### 事务执行过程中可随时加锁，只在执行 COMMIT 或 ROLLBACK 时所有锁同时释放 

##### 是保证可串行化调度的充分条件，但并不保证不会发生死锁。

可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。

#### 锁的算法

Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。

MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。


##### Record Lock

###### 锁定一个记录上的索引，而不是记录本身。

如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Lock 总是会去锁住记录。

###### 若表没设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引

##### Gap Lock

例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。
```
SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;
```

###### 只在REPEATABLE READ 隔离级别下

###### 锁定索引之间的间隙，但是不包含索引本身。

##### Next-Key Lock

它是 Record Lock 和 Gap Lock 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙，是一个前开后闭区间。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：
```
(-∞, 10]
(10, 11]
(11, 13]
(13, 20]
(20, +supremum)
```


###### Record Lock + Gap Lock

###### 当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，降级为Record Lock

###### 防止幻读

#### 并发一致性问题

##### 丢失更新

丢失更新是指一个事务的更新操作会被另一个事务的更新操作所覆盖，导致数据不一致。

######  

T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。

##### Dirty Read（脏读）

脏读是指当前事务读到其他事务未提交的数据。

脏读发生的条件需要事务的隔离级别为READ UNCOMMITTED。

######  

T1 修改一个数据，T2 随后读取这个数据。如果 T1 回滚了这次修改，那么 T2 读取的数据是脏数据。

##### 不可重复读

不可重复读是指一个事务多次读取同一数据可能不一样。

不可重复读和脏读的区别是：脏读是读到未提交的数据，而不可重复读读到的是已提交的数据。

在InnoDB存储引擎中通过使用 Next-Key Lock 算法来避免不可重复读的问题。

######  

T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。

##### 幻读

T1 在未提交前连续两次读取某个范围的数据，而T2在此期间在该范围内插入新的数据，导致T1 连续两次读取的结果不一样。

产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。InnoDB在REPEATABLE READ事务隔离级别下，采用Next-Key Locking的方式来加锁。

###### 图

#######  

###### 解决

####### 可串行化隔离级别

####### REPEATABLE READ隔离级别下，MVCC + Next-Key Lock

### 乐观锁与悲观锁

#### 悲观锁

#### 乐观锁

##### 版本号机制

##### CAS 算法

### MVCC 

#### 特点

##### 行级锁的变种，避免了普通 SELECT 的加锁操作，开销更低

##### 访问数据时加锁，原始数据存于 undo log 中提供快照读，提交失败时恢复 undo log 中的数据

##### 只在 REPEATABLE READ 和 READ COMMITTED 隔离级别下

#### 版本号

##### 系统版本号（SYS_ID）

###### 每开始一个新事务，自动递增

##### 事务版本号（TRX_ID）

###### 事务开始时的系统版本号

##### 每条行记录有两个隐藏列

###### 行创建时间 TRX_ID / SYS_ID

###### 行删除时间 DEL

#### undo 日志

MVCC 的多版本指的是多个版本的快照，快照存储在 Undo 日志中，该日志通过回滚指针 ROLL_PTR 把一个数据行的所有快照连接起来。

##### INSERT、UPDATE、DELETE 时创建

INSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 还会额外将 DEL 字段设置为 1。
```

INSERT INTO t(id, x) VALUES(1, "a");
UPDATE t SET x="b" WHERE id=1;
UPDATE t SET x="c" WHERE id=1;
```

#### ReadView

##### SELECT 时创建，记录当前活跃事务范围

##### SELECT 操作

数据行快照不可用时，沿 Undo log 的回滚指针 ROLL_PTR 找下一快照，再进行判断。

###### TRX_ID < TRX_ID_MIN

####### 可使用

###### TRX_ID > TRX_ID_MAX

####### 不可使用

###### TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX

####### READ COMMITTED 下，事务已提交时可用，否则不可用

####### REPEATABLE READ 下，都不可用

#### 快照读

```
// 普通 SELECT
SELECT ...;
```

##### 读快照的数据，无需加锁

#### 当前读

```

SELECT ... LOCK IN SHARE MODE;
SELECT ... FOR UPDATE;
INSERT;
UPDATE;
DELETE;
```

##### 读最新的数据，需要加锁

### 范式

#### 规范化

关系模式中存在的问题：
- **数据冗余**：数据重复出现，浪费大量的存储空间
- **更新异常（Update Anomalies）**：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。
- **插入异常（Insertion Anomalies）**：如果一个学生函数依赖于系，则无法把一个刚成立、尚无学生的系的信息存入数据库。
- **删除异常（Deletion Anomalies）**：删除一个信息，那么也会丢失其它信息。

规范化理论正是用来改造关系模式，通过分解关系模式来消除其中不合适的数据依赖，以解决插入异常、删除异常、更新异常和数据冗余问题。

一个低一级范式的关系模式，通过**模式分解（schema decomposition）** 可以转换为若干个高一级范式的关系模式的集合，这种过程就叫**规范化（normalization）**。

满足最低要求的叫第一范式1NF。

##### 第一范式(1NF)

关系模式{Sno序号 Sname学生, Sdept学院, Mname院长, Cname课程, Grade分数}

{Sno, Cname} 为主键

函数依赖：
- Sno -> Sname, Sdept （部分依赖）
- Sdept -> Mname （传递依赖）
- Sno, Cname-> Grade （完全依赖）

###### 属性不可分。

##### 第二范式(2NF) 

根据第二范式分解后：

关系1 {Son, Sname, Sdept, Mname}
- Sno -> Sname, Sdept （完全依赖）
- Sdept -> Mname （传递依赖）

关系2 {Sno, Cname, Grade}
- Sno, Cname -> Grade （完全依赖）

###### 非主属性不部分函数依赖于键码。

##### 第三范式(3NF)

关系1根据第三范式分解：

关系-11{Sno, Sname, Sdept}
- Sno -> Sname, Sdept （完全依赖）

关系-12{Sdept, Mname}
- Sdept -> Mname （完全依赖）


###### 非主属性不传递函数依赖于键码。

### SQL 与 NoSQL

## MySQL

### B+ 树

[从B树、B+树、B*树谈到R 树](https://blog.csdn.net/v_JULY_v/article/details/6530142)





#### B树

<!--Note-->
###### B树
B树（B-tree）是一种平衡的多路查找树，结点最大的孩子数目称为B树的阶。
一个m阶的B树具有如下属性：
- 如果根结点不是叶结点，则其至少有两个孩子（子树）。
- 每个非根的分支结点都有k-1个元素和k个孩子，每个叶子结点n都有k-1个元素，其中⌈m/2⌉<=k<= m。
- 所有叶子结点都位于同一层次。
- 所有分支结点包含下列信息数据（n,A₀,K₁,A₁,K₂,A₂,...,Kₙ,Aₙ），其中：
	- Kᵢ(i=1,2,...,n)为关键字，且Kᵢ<Kᵢ₊₁;
    - Aᵢ(i=0,2,...,n)为指向子树根结点的指针，且指针Aᵢ所指子树中所有结点的关键字均小于Kᵢ₊₁，但都大于Kᵢ;
    - 关键字的个数必须满足：n(⌈m/2⌉-1<=n<= m-1)。

对于n个关键字的m阶B树，树的高度*h<= log⌈m/2⌉((n+1)/2)+1*。
<!--/Note-->

##### 与红黑树的差异

###### 减少查找次数

####### 磁盘查找存取的次数由树的高度所决定

树高O(h) = O(logₐN)，其中a为节点出度, 出度越大树高越底, 红黑树出度为2， B树出度远大于2

###### 减少IO次数

####### 一个索引节点 = 一个磁盘块，利用磁盘预读，一次IO载入一个节点

##### 操作

###### 查找时，对每个节点进行二分查找

###### 插入删除会破坏平衡性，需要维护平衡性

#####  

#### B+树

<!--Note-->
###### B+树
一个m阶的B+树和m阶的B树的差异在于：
- 有n棵子树的结点中包含n个关键字；
- 所有的叶子结点包含全部关键字的信息，及指向含有这些关键字记录的指针，叶子结点本身依关键字的大小自小到大顺序链接；
- 所有分支结点可以看成是索引，结点中仅含有其子树中的最大（或最小）关键字。

B+树相较于B树的优点：
- **B+-tree的磁盘读写代价更低**：B+-tree的内部结点并没有指向关键字具体信息的指针。
- **B+-tree的查询效率更加稳定**：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路，导致每一个数据的查询效率相当。
<!--/Note-->

##### 与B树的差异

###### IO代价更低

####### 内部节点不含data域，盘块可存更多键值，出度更大

B+树内部结点只含索引列值和指针，不含对应行其他信息

###### 查询更稳定

####### 每次查询都要走到叶子节点

###### 叶子节点可实现遍历

#####  

######  

### 索引以及优化

#### 特点

##### 优点

###### 减少服务器扫描数据量，提高检索速度

####### B+树查找代替全表扫描

###### 随机 I / O 变顺序 I / O

####### 范围查询时，减少磁盘寻道

###### 帮助服务器避免排序和临时表

####### 排序和分组时，不需要建临时表

##### 缺点

###### 占物理空间

###### 降低增删改速度

####### 要维护B+树平衡

#### 哈希索引

把键值换算成新的哈希值，根据这个哈希值来定位

##### 无法排序

##### 只支持等值比较，不支持范围查询

##### 只含哈希值和行指针，不存字段值, 需要再去磁盘查找

##### 联合索引 (a, b) 全部列计算哈希值，不能只查询a

##### 速度快，但哈希冲突多时维护代价高

##### InnoBD使用自适应哈希索引

在B+树上给频繁索引值加哈希索引。

#### 最左匹配原则

最左开始匹配连续索引，直至范围查询。

##### 联合索引 (a, b), 最左字段构建B+树，a全局有序，b局部有序，若a值是一个范围，范围内b不一定有序

##### 无需考虑 =、in 顺序，mysql自动优化

#### 索引策略

##### 聚簇索引

###### 主键创建的索引

###### 叶子节点 -> 表中行数据

###### 优点

####### 数据保持在一起，范围查找只需少量I/O

####### 数据访问更快，索引与数据在同一B+树中

##### 非聚簇索引

###### InnoDB索引

####### 二级索引

######## 非主键创建的索引

######## 叶子节点 -> 主键值 + 索引列值

###### MyISAM索引

####### 主键或非主键创建

####### 叶子节点 -> 行指针 + 索引列值 

##### 覆盖索引

```
//查询的列与索引对应
select username , age 
from user 
where username = 'Java3y' 
and age = 20;
```

###### InnoDB二级索引无需回表

###### 把随机IO变成顺序IO加快查询效率 

###### MyISAM只缓存索引，只需一次系统调用

###### 只读索引不读数据，减少数据访问量

#####  

######  

#### 索引优化

##### 索引使用场合

###### where

###### order

###### join

###### 覆盖索引

##### 优化

###### 字段要独立存在

```
# 索引失效
select * from user where id+1 = 20; 
```
```
# 索引有效
select * from user where id = 20-1;
```


###### like，不能以通配符%开头

```
 # 索引失效
select * from article where title like '%mysql%';
```
```
 # 索引有效
select * from article where title like 'mysql%';
```

###### or, 需要两边条件都有索引

###### 索引列设置为 NOT NULL ，否则将导致索引失效进行全表扫描

###### 联合索引注意最左匹配原则

###### 不要在索引列上进行计算

###### 注意避免冗余索引

查询 sys 库的 schema_redundant_indexes 表来查看冗余索引

### 查询优化

#### explain 分析 select 

##### select_type

###### 查询类型，有简单查询、联合查询、子查询等

##### key

###### 使用的索引

##### rows

###### 扫描的行数

##### possible_keys

###### 可选的索引

#### 优化数据访问

##### 只返回必要列：最好不要使用 SELECT *

##### 只返回必要行：使用LIMIT限制 

##### 缓存重复查询的数据

##### 使用索引查询

### InnoDB 与 MyISAM

#### InnoDB

##### 支持事务

##### 支持外键

##### 主键索引是聚簇索引

###### 索引中保持数据，避免直接读磁盘

##### 支持在线热备份，崩溃后可安全恢复

##### 支持行级锁，，采用MVCC来支持高并发

#### MyISAM

##### 对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用

##### 支持BLOB和TEXT的前500个字符索引，支持全文索引

##### 在表有读取查询的同时，支持往表中插入新纪录

### 水平切分与垂直切分

#### 水平切分

##### 保持数据表结构不变，通过策略存储数据分片

##### 优点

###### 支持非常大的数据量存储

###### 应用端改造较少

###### 提高了系统的稳定性和负载能力

##### 缺点

###### 分片事务一致性难以解决

###### 跨库Join性能差，逻辑复杂

###### 数据多次扩展难度跟维护量极大

#####  

#### 垂直切分

##### 根据数据库里面数据表的相关性进行拆分

##### 优点

###### 使得列数据变小，数据块可存放更多数据，在查询时减少I/O次数。

###### 将常改和不常改的字段分开，可最大化利用Cache

###### 数据维护简单

##### 缺点

###### 主键出现冗余，需要管理冗余列

###### 会引起表连接JOIN操作（增加CPU开销）

###### 依然存在单表数据量过大的问题（需要水平拆分）

###### 事务处理复杂

#####  

### 复制

#### 主从复制

##### binlog 线程

###### 负责将主服务器上的数据更改写入二进制日志（Binary log）中

##### I/O 线程

###### 负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）

##### SQL 线程

###### 负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。

#####  

#### 读写分离

##### 优点

###### 主从服务器负责各自的读和写，极大程度缓解了锁的争用；

###### 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；

###### 增加冗余，提高可用性。

##### 代理方式来实现

######  

### 日志

## Redis

### 字典和跳跃表

#### 字典（hash）

```
typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2]; /* 两个哈希表，用于rehash操作 */
    long rehashidx; /* 记录rehash目前进行到的桶下标 */
    unsigned long iterators; /* number of iterators currently running */
} dict;
```

```
// 哈希表
typedef struct dictht {
    dictEntry **table; /* 哈希表数组 */
    unsigned long size; /* table数组大小 */
    unsigned long sizemask; /* size - 1，用于计算桶下标 */
    unsigned long used; /* 已有节点数量 */
} dictht;
```

```
// 哈希表节点
typedef struct dictEntry {
    void *key; /* 键 */
    union { /* 值 */
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;  /* 下一节点 */
} dictEntry;
```

##### 渐进式 rehash

```
/* 执行 n 步渐进 rehash, 完成返回 0, 未完成返回 1 */
int dictRehash(dict *d, int n) {
    int empty_visits = n * 10; /* 可访问的最大空桶数 */
    if (!dictIsRehashing(d)) return 0;
	
    /* n 步 rehash */
    while (n-- && d->ht[0].used != 0) {
        dictEntry *de, *nextde;

        /* rehash索引 < 桶总数 */
        assert(d->ht[0].size > (unsigned long) d->rehashidx);
        
        /* 跳过空桶 */
        while (d->ht[0].table[d->rehashidx] == NULL) {
            d->rehashidx++;
            if (--empty_visits == 0) return 1;
        }
        
         /* 旧表该下标桶上所有键重新计算下标并移到新表上 */
        de = d->ht[0].table[d->rehashidx];
        while (de) {
            uint64_t h;

            nextde = de->next;
            /* Get the index in the new hash table */
            h = dictHashKey(d, de->key) & d->ht[1].sizemask;
            de->next = d->ht[1].table[h];
            d->ht[1].table[h] = de;
            d->ht[0].used--;
            d->ht[1].used++;
            de = nextde;
        }
        d->ht[0].table[d->rehashidx] = NULL;
        d->rehashidx++;
    }

    /* 检查是否已 rehash 完 */
    if (d->ht[0].used == 0) {
        zfree(d->ht[0].table);
        d->ht[0] = d->ht[1];
        _dictReset(&d->ht[1]);
        d->rehashidx = -1;
        return 0;
    }

    /* 未完待续... */
    return 1;
}

```

###### 扩容或收缩时的 rehash 不是一次性完成的，而是分多次完成，防止 rehash 太长影响服务器性能

#### 跳跃表（Sorted Set）

跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

#####  

##### 插入

###### 新节点随机一个层数后插入，只需更改节点前后指针

##### 查找

###### 从上层开始查找，找到对应区间后进入下一层查找

##### 与红黑树对比

###### 插入速度非常快，无需进行旋转等操作维护平衡性

###### 更容易实现

###### 并发修改时，跳表可用cas操作节点，红黑树需锁首节点

### 使用场景

#### String

可以作为数字进行自增自减 
```
set, get, decr, incr, mget 
```

##### 计数器：微博数，粉丝数

##### 缓存热点数据

##### 共享Session

#### Hash

适用于存储对象
```
hget, hset, hgetall 
```

##### 存储用户信息、商品信息等

#### List

双向链表，支持反向查找和变量
```
lpush, rpush, lpop, rpop, lrange
```

##### 微博关注列表，粉丝列表等

##### 消息队列

##### lrange实现分页查询

#### Set

自动重排随机弹出，可实现交集、并集、差集操作
```
sadd, spop, smembers, sunion
```

##### 抽奖

##### 共同关注、共同好友等

#### Sorted Set

元素能够按score进行有序排序
```
zadd, zrange, zrem, zcard
```

##### 排行榜

#### 其他

##### 会话缓存

###### 统一存储多台应用服务器的会话信息

##### 分布式锁实现

###### SETNX命令实现或RedLock分布式锁实现

##### 查找表

###### 如 DNS 记录，与缓存类似，但内容不会失效

### 与 Memcached 的比较

#### Redis支持5种不同的数据类型，Memcached仅支持String

#### Redis支持数据持久化，Memcached全部数据存于内存中

#### Redis Cluster支持分布式，Memcached只能通过客户端使用一致性哈希实现分布式存储

#### Redis使用单线程、多路IO复用模式，Memcached使用多线程、非阻塞IO模式

####  

#####  

### RDB 和 AOF 持久化机制

#### RDB持久化

快照（snapshotting）持久化：将某个时间点的所有数据快照以 RDB 文件的形式保存到硬盘。

持久化时会调用 fork 函数产生一个子进程。
```
pid = os.fork()
if pid > 0:
  handle_client_request()  # 父进程继续处理客户端请求
if pid == 0:
  handle_snapshot_write()  # 子进程处理快照写磁盘
if pid < 0:  
  # fork error

```


##### 默认持久化方式

##### redis.conf 配置

```
# 在900秒(15分钟)后，若至少有1个key发生变化, 则触发BGSAVE命令重写RDB文件
save 900 1    

# 在300秒(5分钟)后，若至少有10个key发生变化，则触发BGSAVE命令重写RDB文件
save 300 10   

# 在60秒(1分钟)后，若至少有10000个key发生变化，则触发BGSAVE命令重写RDB文件
save 60 10000 

```

##### 快照备份

###### 可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。

###### 可以将快照留在原地以便重启服务器的时候使用。

##### 优缺点

###### RDB 持久化能够快速地储存和恢复数据， 但是在服务器停机时却会丢失大量数据；

#### AOF持久化

只追加文件（append-only file）持久化：将写命令添加到 AOF 文件的末尾。

##### 实时性更好，主流的持久化方案

##### appendfsync参数

因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。

###### always

####### 每个写命令都同步

####### 会严重减低服务器的性能

###### everysec

####### 每秒同步一次

####### 对性能几乎没影响，崩溃时最多只丢失1秒的数据

###### no

####### 让操作系统来决定何时同步

####### 并不能给服务器性能带来多大的提升，且也会增加系统崩溃时数据丢失量。

##### AOF 重写

###### 随着服务器写请求的增多，AOF 文件会越来越大。

###### 创建一个新AOF文件替代现有AOF文件，新旧文件所保存的数据库状态相同，但新AOF文件不含冗余命令，体积小很多

使用子线程创建新AOF文件，并创建重写缓冲区保存创建期间产生的写命令，新AOF创建完后，重写缓冲区内容追加到新AOF中，保证新旧AOF文件数据库状态一致。

##### 优缺点

###### AOF 持久化能够有效地提高数据的安全性， 但是在储存和恢复数据方面却要耗费大量的时间。

#### Redis 4.0 的 RDB 和 AOF 混合持久化

##### 利用 AOF 重写，直接把 RDB 的内容写到 AOF 文件开头，增量AOF日志放在末尾。

##### 优缺点

###### 快速加载同时避免丢失过多的数据，只是AOF文件里的RDB部分可读性较差

### 数据淘汰机制

#### 设置过期时间

##### 定期删除

###### 默认每100ms随机抽取一些key并删除过期的

##### 惰性删除

###### 没定期删除的过期key在被查找时会删除

#### 6种淘汰机制

##### volatile-lru

###### 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰

##### volatile-ttl

###### 从已设置过期时间的数据集中挑选将要过期的数据淘汰

##### volatile-random

###### 从已设置过期时间的数据集中任意选择数据淘汰

##### allkeys-lru

###### 当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key

##### allkeys-random

###### 从所有数据集中任意选择数据进行淘汰

##### noeviction

###### 禁止驱逐数据

#### Redis 4.0

##### volatile-lfu

###### 从已设置过期时间的数据集中挑选最不经常使用的数据淘汰

LRU（Least Recently Used）：最近最久未使用策略，淘汰上次被访问时间距离现在最久的数据
LFU（Least Frequently Used）：最不经常使用策略，淘汰最近一段时间内使用次数很少的数据


##### allkeys-lfu

###### 当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key

### 缓存问题

#### 缓存穿透

##### 场景

###### 大量查询不存在的数据 -> 大量请求直达数据库，造成存储层宕机

##### 解决

###### 缓存无效key

#######  如果缓存和数据库都查不到某个 key 的数据，就写一个到 redis 中去并设置过期时间

###### 布隆过滤器

####### 将所有存在的key提前存入布隆过滤器，在访问缓存层前，先通过过滤器拦截，若请求的key不存在，返回空值

##### 

######  

#### 缓存击穿

##### 场景

###### 一份非常热点的数据在缓存失效瞬间 -> 大量请求直达数据库，造成存储层宕机

##### 解决

###### 互斥加锁

####### 对数据的访问加互斥锁，一个线程访问过后，缓存中数据重建，其他线程就可直接从缓存取值

###### 永不过期

####### 不设置过期时间或只为value设置逻辑过期时间

#### 缓存雪崩

##### 场景

###### 缓存同一时间大面积失效 -> 大量请求直达数据库，造成存储层宕机

##### 解决

###### 避免同时过期

####### 在过期时间后加个随机数，避免大量key同时过期

###### 构建高可用Redis缓存集群

####### 部署多个Redis实例，个别节点宕机，仍可保存服务整体可用

###### 构建多级缓存

####### 增加本地缓存，在存储层前面多加一级屏障，降低请求直达存储层的几率

###### 启动限流和降级服务

####### 对数据库增加 hystrix 限流 & 降级措施，当请求超出限制时，对其提供降级服务

##### 

######  

#### 缓存与数据库双写的数据一致性

##### 方法

###### 读请求和写请求串行化，串到一个内存队列里去

####### 会导致系统的吞吐量大幅度降低

###### Cache Aside Pattern

####### 读数据时，先读缓存，缓存没有则读数据库，数据放入缓存并返回响应

####### 更新时，先更新数据库，再删除缓存

##### 问题

###### 为什么是删除缓存而不是更新

####### 缓存更新可能需要额外查表并做复杂计算

####### 多写少读时，会导致过多无用的复杂计算

###### 先更新数据库，还是先删除缓存

####### 先更新数据库，但缓存删除失败，缓存中一直是旧数据

####### 先删除缓存，且未修改完数据库，此时读并缓存旧数据，仍会导致不一致

读写串行化可解决

### Redis 事务

####  MULTI 开始事务，多个命令放入队列缓存中， 由 EXEC 触发事务执行队列中所有命令

#### 事务失败处理

##### 若事务队列中存在命令拼写错误（编译性错误），则执行EXEC时，所有命令都不执行

##### 若事务队列中存在类型操作错误（运行时异常），则执行EXEC时，其他正确命令执行，错误命令抛出异常。

#### Redis没有回滚，不保证原子性

### Redis线程模型

#### 文件事件处理器

##### 基于Reactor模式开发了自己的网络事件处理器，单线程

##### 既实现高性能的网络通信模型， 又很好地与 redis 服务器中单线程模块进行对接， 保持 Redis 内部单线程设计的简单性。

##### 组成 

###### 套接字、I/O多路复用程序、文件事件分派器、事件处理器 

#### 文件事件

##### 客户端对socket执行write、close操作或对serverSocket执行connect操作时，产生AE_READABLE事件；

##### 客户端对socket执行read操作时，产生AE_WRITABLE事件

#### I/O多路复用程序

##### 监听多个socket，将产生事件的socket放入队列

#### 文件事件分派器

##### 从队列中接受socket，根据socket产生的事件类型，调用相应的事件处理器

#### 事件处理器

##### 连接答应处理器

######  

##### 命令请求处理器

######  

##### 命令回复处理器

######  

####  

#####  

### 分布式锁

#### 基于数据库实现

#### 基于 Redis 实现

##### 安全性和活性保证

###### 互斥

####### 任何时刻只能有一个客户端获得锁

###### 无死锁

####### 即使持有锁的客户端崩溃或出现网络分区，锁仍然可以被获取

###### 容错

####### 只要大部分 Redis 节点都活着，客户端就可以获取和释放锁

##### Redis 分布式锁的问题

###### 锁超时

两台平行的服务 A B，如果 A 服务在获取锁之后突然挂了，那么 B 服务就永远无法获取到锁，因此需要额外设置一个超时时间，保证服务的可用性

####### 任务的执行时间不能超过锁的超时时间

####### 将锁的 value 设为一个随机数，释放锁时先匹配随机数再删除 key

确保当前进程占有的锁不会被其他进程释放，除非这个锁是因为过期了而被服务器自动释放的。

####### Lua 脚本保证匹配 value 和删除 key 的原子性执行

######## 可以避免删除别的客户端获取的锁

A匹配 value 成功后，A突然阻塞，锁超时释放，B加锁，A 恢复并删除 key，使得B获得的锁被释放

###### 单点 / 多点问题

####### 单机部署模式 Redis 故障会导致整个服务不可用。

####### 主从模式部署 Redis 在主机宕机时可以用 RedLock 算法从从机获得锁

##### 单 Redis 实例实现

###### 使用命令获取锁

```
SET resource_name my_random_value NX PX 30000
```
resource_name: 锁的 key
my_random_value: 随机值
NX: 仅在 key 不存在时才执行成功。
PX 30000: 设置锁的自动过期时间。

###### 使用 Lua 脚本释放锁

```
if redis.call("get", KEYS[1]) == ARGV[1]
then return redis.call("del", KEYS[1])
else return 0
end
```	

##### 多 Redis 实例实现

###### Redlock 算法

####### 1. 获得当前时间戳（单位毫秒）

####### 2. 依次尝试N个实例: 使用相同的 key 和随机值并在一个超时时间内获得锁，超时未获得则跳过

####### 3. 若客户端获得大多数实例的锁（N / 2 + 1), 且总消耗时间小于锁有效时间，则获得锁成功

总消耗时间 = 当前时间戳 - 步骤1的时间戳

####### 4. 若锁获得成功，锁真正有效时间 = 锁有效时间 - 总消耗时间

####### 5. 若锁获得失败，对所有实例进解锁

#### 基于 Zookeeper 实现

### 主从复制

#### 连接过程

##### 主服务器发送快照给从服务器，发送期间用缓冲区记录写命令，快照发完后发缓冲区的写命令

##### 从服务器丢弃旧数据，载入发来的快照和缓冲区写命令

##### 之后，主服务器每执行一次写命令，就向从服务器发送相同的写命令

#### 主从链

##### 创建一个中间层来分担主服务器的复制工作

随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。

######  

#### 优点

##### 数据冗余

###### 持久化之外的一种数据冗余方式

##### 故障恢复

###### 主节点故障，可由从节点提供服务

##### 负载均衡

###### 配合读写分离，由主节点提供写服务，从节点提供读服务

##### 高可用基石

###### 是哨兵和集群能够实施的基础

#### 缺点

##### 从节点晋升主节点时，更改主节点地址和其他从节点复制新的主节点，这一过程都要人工干预

##### 主节点的写能力和存储能力都受到单机限制

##### 复制中断后，从节点发起同步但不成功时，会进行全量同步，造成卡顿

### Redis Sentinel 哨兵

####  哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的 Redis 节点，不存储数据

#### 自动化的故障恢复

##### 监控（Monitoring）

###### 哨兵会不断地检查主节点和从节点是否运作正常

##### 自动故障转移（Automatic failover）

###### 主节点故障时，让其某个从节点升级为主节点，并让其他从节点改为复制新的主节点

##### 配置提供者（Configuration provider）

######  客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址

##### 通知（Notification）

###### 哨兵可以将故障转移的结果发送给客户端

####  

#####  

### Redis 集群

#### Redis Cluster 集群的主要作用

##### 数据分区

###### 突破了 Redis 单机内存大小的限制，存储容量大大增加

######  每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力

##### 高可用

###### 集群支持主从复制和主节点的 自动故障转移 

#### 数据分区

把 数据集 划分到 多个节点 上，每个节点负责 整体数据 的一个 子集

##### 分区方式

###### 顺序分区

####### 将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上

####### 保持数据原有的顺序，并能准确控制每个节点的数据量，但需要维护一张映射范围表，维护代价高

###### 哈希分区

####### 根据 hash(key) % N 决定数据映射的节点，

####### 简单，但节点数 N 变化时，需要重新计算映射关系，导致大量数据重新迁移

##### 改进的哈希分区方式

###### 一致性哈希

将哈希空间 [0, 2^n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。

#######  

####### 原理

######## 每个服务器节点都配置到哈希空间 [0, 2^n-1] 的哈希环上

######## 每个数据取哈希值后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上

######## 增加或者删除节点时，只会影响哈希环中顺时针方向的相邻节点

####### 优点

######## 克服了传统哈希分布在服务器节点数量变化时大量数据迁移的问题。

####### 缺点

使用虚拟节点可解决


######## 增减节点时会造成哈希环中部分数据无法命中

######## 节点很少时，节点变化会大范围影响哈希环中的数据映射

######## 增减节点时需要增加一倍或减少一半节点，才能保证数据和负载的均衡

###### 虚拟槽

####### 使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数（槽）集合中

这个范围一般远远大于节点数

####### 每个节点负责一定数量的槽，大范围槽方便数据拆分和集群扩展

####### 优点

######## 数据分布更加均匀

######## 容易添加和删除节点，只需移动部分槽

######## 从一个节点将 哈希槽 移动到另一个节点并不会 停止服务

依赖主从复制

#######  

##### Redis 数据分区方式

###### Redis Cluster 采用 虚拟槽分区， slot = CRC16（key）& 16383

###### 特点

####### 解耦 数据 和 节点 之间的关系，简化了节点 扩容 和 收缩 难度

####### 节点自身 维护槽的 映射关系，不需要 客户端 或者 代理服务 维护 槽分区元数据

####### 支持 节点、槽、键 之间的 映射查询，用于 数据路由、在线伸缩 等场景

#### Redis集群方案

##### 客户端分区（jedis）

###### 客户端使用一致性哈希等算法决定键应当分布到哪个节点

#######  

##### 代理分区（Twemproxy 和 Codis）

###### 将客户端请求发送到代理上，由代理转发请求到正确的节点上

#######  

##### 路由查询分区（Redis Cluster）

###### 客户端请求任意一个节点，然后由 Redis 将请求转发给正确的节点

#######  
